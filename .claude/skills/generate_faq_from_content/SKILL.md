---
name: generate_faq_from_content
description: 基于大语言模型的智能FAQ生成器，支持全量内容分析和多维度问题生成
version: 2.0.0
tools: [Read, Write, LLM]
---

# generate_faq_from_content - 智能FAQ生成器 v2.0

## 🎯 核心功能

基于深度内容分析和用户意图预测，从知识内容中自动识别潜在问题点，提取对应答案，生成标准问答对并分类整理。

## 📋 工作流SOP

**工作流SOP**：
```
1. 接收内容输入
2. 识别潜在问题点
3. 提取对应答案
4. 生成标准问答对
5. 验证问答质量
6. 执行覆盖度检测
7. 评估覆盖度达标情况
8. 如未达标，大模型重新挖掘缺失内容
9. 持续循环检测直至覆盖度达标
10. 分类整理FAQ
11. 返回FAQ集合
```

### 详细流程说明

**步骤1：接收内容输入**
- 验证源内容的完整性和有效性
- 检查目标用户定义的合理性
- 解析覆盖要求和质量标准
- 记录内容基本信息

**步骤2：识别潜在问题点**
- 分析内容中的关键概念和规则
- 识别可能产生疑问的复杂点
- 提取需要解释的政策条款
- 生成候选问题列表

**步骤3：提取对应答案**
- 从内容中提取问题的答案
- 确保答案的准确性和完整性
- 提取相关的上下文信息
- 生成答案候选集合

**步骤4：生成标准问答对**
- 将问题和答案配对
- 标准化问题表述方式
- 优化答案的表达清晰度
- 生成标准FAQ格式

**步骤5：验证问答质量**
- 检查答案与源内容的一致性
- 验证问题的覆盖度
- 评估问答的实用性
- 计算置信度评分

**步骤6：执行覆盖度检测**
- 调用 [`faq_completeness_checklist.py`](scripts/faq_completeness_checklist.py) 脚本
- 检测FAQ对原始文档的章节覆盖情况
- 分析关键点覆盖率和优先级覆盖情况
- 生成覆盖度检测报告和改进建议

**步骤7：评估覆盖度达标情况**
- 判断章节覆盖率是否≥80%
- 验证关键点覆盖率是否≥85%
- 确认高优先级章节是否100%覆盖
- 计算总体覆盖度得分

**步骤8：如未达标，大模型重新挖掘缺失内容**
- 当覆盖度检测未达标时，大模型分析未覆盖章节
- 针对缺失的关键章节和知识点进行深度挖掘
- 生成补充的FAQ内容
- 将新生成的FAQ整合到现有集合中

**步骤9：持续循环检测直至覆盖度达标**
- 调用 [`auto_faq_enrichment.py`](scripts/auto_faq_enrichment.py) 脚本
- 自动循环执行覆盖度检测和补充流程
- 最多支持5次迭代优化
- 每次迭代自动补充缺失内容并重新检测
- 当覆盖度达到标准或达到最大迭代次数时停止

**步骤10：分类整理FAQ**
- 按照主题对FAQ分类
- 建立FAQ之间的关联关系
- 优化FAQ的组织结构
- 生成分类索引

**步骤11：返回FAQ集合**
- 生成结构化的FAQ列表
- 包含问题、答案、分类、置信度
- 提供覆盖分析和质量评分
- 返回完整的FAQ集合

## 📋 输入规范

### 必需输入
```json
{
  "document_content": "完整的文档内容",
  "target_audience": "目标用户群体（如：全体员工、新员工、管理层）"
}
```

### 可选输入
```json
{
  "document_type": "文档类型（policy/manual/guide）",
  "depth_level": "挖掘深度（basic/standard/comprehensive）",
  "max_questions": "最大生成问题数量（默认：50）",
  "focus_areas": ["重点关注领域列表"]
}
```

## 📤 输出内容

### FAQ集合
```json
{
  "faq_collection": [
    {
      "question": "问题文本",
      "answer": "答案文本",
      "category": "问题分类",
      "confidence": 0.95,
      "source_section": "来源章节",
      "question_type": "概念解释",
      "user_intent": "了解公司基本信息"
    }
  ],
  "metadata": {
    "total_questions": 25,
    "coverage_score": 0.92,
    "quality_score": 0.89,
    "processing_time": 12.5
  }
}
```

## 🎪 使用示例

### 示例1: 从员工手册生成FAQ
```
使用 generate_faq_from_content 从员工手册生成FAQ
文档内容：员工手册完整内容
目标用户：全体员工
挖掘深度：comprehensive
最大问题数：50
```

### 示例2: 重点关注某些领域
```
使用 generate_faq_from_content 生成绩效考核FAQ
文档内容：绩效管理制度
目标用户：全体员工
重点关注：考核标准、考核流程、申诉机制
```

## 🔧 配置选项

### 生成策略配置
```yaml
generation:
  depth_level: comprehensive
  max_questions: 50
  question_types: [concept, process, rule, obligation, scenario]
  coverage_threshold: 0.85
```

## 📊 质量指标

- **内容覆盖率**: ≥ 90%（目标值）
- **问题相关性**: ≥ 85%（目标值）
- **答案准确性**: ≥ 95%（目标值）
- **生成效率**: ≤ 15秒/文档（目标值）

## ⚠️ 注意事项

### 质量保证
- 生成后建议人工审核
- 定期更新以保持时效性
- 收集用户反馈持续优化

### 覆盖度保证机制
- **自动检测**：通过完整性检查脚本自动识别未覆盖的重要章节
- **循环优化**：使用 [`auto_faq_enrichment.py`](scripts/auto_faq_enrichment.py) 持续循环检测，确保覆盖度达标
- **大模型补充**：当检测到重要章节未覆盖时，大模型分析缺失内容并重新生成
- **质量标准**：确保章节覆盖率≥80%，关键点覆盖率≥85%，高优先级章节100%覆盖

### 技术实现
- **完整性检查**：调用 [`faq_completeness_checklist.py`](scripts/faq_completeness_checklist.py) 验证FAQ覆盖度
- **自动补充**：调用 [`auto_faq_enrichment.py`](scripts/auto_faq_enrichment.py) 实现持续循环检测和补充
- **质量评估**：综合计算总体得分，确保达到目标标准（默认0.7）
- **迭代优化**：支持最多5次迭代，自动补充缺失内容直到满足要求

### 大模型工作模式
- **决策驱动**：大模型基于检查结果做出补充决策，而非自动执行
- **内容生成**：大模型专注于FAQ内容的质量和准确性
- **流程指导**：大模型指导整个工作流程，确保每个环节的质量
- **结果优化**：大模型根据反馈持续优化生成策略

---

**generate_faq_from_content v2.0** - 智能FAQ生成，让知识服务更高效！ 🚀