#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FAQå®Œæ•´æ€§æ£€æŸ¥æ¸…å•
ç”¨äºéªŒè¯ä»æ–‡æ¡£ç”Ÿæˆçš„FAQæ˜¯å¦å®Œæ•´è¦†ç›–äº†å…³é”®å†…å®¹
"""

from typing import Dict, List, Any, Optional
import json
import re
import sys
import argparse
import os
import logging
from dataclasses import dataclass, asdict
from enum import Enum

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

try:
    import PyPDF2
    PDF_SUPPORT = True
except ImportError:
    PDF_SUPPORT = False
    logger.warning("PyPDF2æœªå®‰è£…ï¼ŒPDFæ–‡ä»¶æ”¯æŒå°†ä¸å¯ç”¨ã€‚è¯·è¿è¡Œ: pip install PyPDF2")


class DocumentType(Enum):
    """æ–‡æ¡£ç±»å‹æšä¸¾"""
    EMPLOYEE_HANDBOOK = "employee_handbook"
    POLICY_DOCUMENT = "policy_document"
    OPERATION_GUIDE = "operation_guide"
    PRODUCT_MANUAL = "product_manual"


@dataclass
class CompletenessCheckResult:
    """å®Œæ•´æ€§æ£€æŸ¥ç»“æœ"""
    document_type: str
    total_sections: int
    covered_sections: int
    section_coverage_rate: float
    total_key_points: int
    covered_key_points: int
    key_point_coverage_rate: float
    faq_count: int
    min_faq_count_met: bool
    priority_coverage: Dict[str, bool]
    overall_score: float
    recommendations: List[str]
    covered_section_names: List[str] = None
    uncovered_section_names: List[str] = None
    
    def __post_init__(self):
        if self.covered_section_names is None:
            self.covered_section_names = []
        if self.uncovered_section_names is None:
            self.uncovered_section_names = []


class FAQCompletenessChecker:
    """FAQå®Œæ•´æ€§æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.checklist_templates = self._load_checklist_templates()
        self.stats = {
            "total_faqs": 0,
            "sections_checked": 0,
            "key_points_checked": 0
        }
    
    def _load_checklist_templates(self) -> Dict[str, Any]:
        """åŠ è½½æ£€æŸ¥æ¸…å•æ¨¡æ¿"""
        return {
            DocumentType.EMPLOYEE_HANDBOOK.value: {
                "name": "å‘˜å·¥æ‰‹å†Œæ£€æŸ¥æ¸…å•",
                "sections": [
                    {"name": "å…¬å¸æ¦‚å†µ", "priority": "high", "key_points": ["å…¬å¸ä»‹ç»", "ä¼ä¸šæ–‡åŒ–", "ä¸šåŠ¡èŒƒå›´"]},
                    {"name": "æ€»åˆ™", "priority": "high", "key_points": ["é€‚ç”¨èŒƒå›´", "å‘˜å·¥å®šä¹‰", "æ‰‹å†Œæ•ˆåŠ›"]},
                    {"name": "å‘˜å·¥è˜ç”¨", "priority": "high", "key_points": ["è˜ç”¨åŸåˆ™", "æ‹›è˜æµç¨‹", "å…¥èŒææ–™"]},
                    {"name": "åŠ³åŠ¨åˆåŒ", "priority": "high", "key_points": ["åˆåŒç±»å‹", "ç­¾è®¢è¦æ±‚", "ç‰¹æ®Šæƒ…å½¢"]},
                    {"name": "è¯•ç”¨æœŸç®¡ç†", "priority": "high", "key_points": ["è¯•ç”¨æœŸæœŸé™", "è€ƒæ ¸æ ‡å‡†", "ä¸ç¬¦åˆå½•ç”¨æ¡ä»¶"]},
                    {"name": "è€ƒå‹¤ä¼‘å‡", "priority": "high", "key_points": ["å·¥ä½œæ—¶é—´", "è€ƒå‹¤æ–¹å¼", "è¿Ÿåˆ°æ—©é€€", "æ—·å·¥", "å„ç±»å‡æœŸ"]},
                    {"name": "åŠ³åŠ¨åˆåŒè§£é™¤", "priority": "medium", "key_points": ["è§£é™¤æ¡ä»¶", "è§£é™¤æµç¨‹", "ç»æµè¡¥å¿"]},
                    {"name": "å¥–æƒ©ç®¡ç†", "priority": "medium", "key_points": ["å¥–åŠ±ç±»å‹", "å¤„ç½šç±»å‹", "é€‚ç”¨æƒ…å½¢"]},
                    {"name": "å»‰æ´æ‰¿è¯º", "priority": "high", "key_points": ["è¡Œä¸ºè§„èŒƒ", "ç¦æ­¢è¡Œä¸º", "ä¸¾æŠ¥æ–¹å¼"]},
                    {"name": "å…¥èŒæŒ‡å¼•", "priority": "high", "key_points": ["åŠç†äº‹é¡¹", "ç³»ç»Ÿç™»å½•", "ä¿¡æ¯é‡‡é›†"]},
                    {"name": "è–ªé…¬ç¦åˆ©", "priority": "high", "key_points": ["è–ªèµ„ç»“æ„", "äº”é™©ä¸€é‡‘", "å•†ä¸šä¿é™©", "è–ªèµ„å‘æ”¾"]}
                ],
                "min_faq_count": 30,
                "coverage_threshold": 0.8
            },
            DocumentType.POLICY_DOCUMENT.value: {
                "name": "æ”¿ç­–æ–‡æ¡£æ£€æŸ¥æ¸…å•",
                "sections": [
                    {"name": "æ”¿ç­–ç›®çš„", "priority": "high", "key_points": ["åˆ¶å®šèƒŒæ™¯", "é€‚ç”¨èŒƒå›´", "æ”¿ç­–ç›®æ ‡"]},
                    {"name": "æ”¿ç­–å†…å®¹", "priority": "high", "key_points": ["æ ¸å¿ƒæ¡æ¬¾", "æ‰§è¡Œæ ‡å‡†", "ä¾‹å¤–æƒ…å†µ"]},
                    {"name": "æ‰§è¡Œæµç¨‹", "priority": "high", "key_points": ["ç”³è¯·æµç¨‹", "å®¡æ‰¹æµç¨‹", "æ“ä½œæµç¨‹"]},
                    {"name": "è´£ä»»åˆ†å·¥", "priority": "medium", "key_points": ["éƒ¨é—¨èŒè´£", "å²—ä½èŒè´£", "ç›‘ç£è´£ä»»"]},
                    {"name": "è¿è§„å¤„ç†", "priority": "medium", "key_points": ["è¿è§„æƒ…å½¢", "å¤„ç†æªæ–½", "ç”³è¯‰æ¸ é“"]}
                ],
                "min_faq_count": 15,
                "coverage_threshold": 0.85
            }
        }
    
    def check_completeness(self, document_type: str, faq_data: List[Dict], 
                          source_content: str) -> CompletenessCheckResult:
        """
        æ£€æŸ¥FAQå®Œæ•´æ€§
        
        Args:
            document_type: æ–‡æ¡£ç±»å‹
            faq_data: FAQæ•°æ®åˆ—è¡¨
            source_content: æºæ–‡æ¡£å†…å®¹
        
        Returns:
            å®Œæ•´æ€§æ£€æŸ¥ç»“æœ
        """
        if document_type not in self.checklist_templates:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡æ¡£ç±»å‹: {document_type}")
        
        template = self.checklist_templates[document_type]
        
        # åˆ†æç« èŠ‚è¦†ç›–æƒ…å†µ
        section_coverage = self._check_section_coverage(template["sections"], faq_data, source_content)
        
        # åˆ†æå…³é”®ç‚¹è¦†ç›–æƒ…å†µ
        key_point_coverage = self._check_key_point_coverage(template["sections"], faq_data, source_content)
        
        # æ£€æŸ¥FAQæ•°é‡
        faq_count = len(faq_data)
        min_faq_count_met = faq_count >= template["min_faq_count"]
        
        # è®¡ç®—ä¼˜å…ˆçº§è¦†ç›–
        priority_coverage = self._check_priority_coverage(template["sections"], section_coverage)
        
        # è®¡ç®—æ€»ä½“å¾—åˆ†
        overall_score = self._calculate_overall_score(
            section_coverage["coverage_rate"],
            key_point_coverage["coverage_rate"],
            faq_count,
            template["min_faq_count"],
            priority_coverage
        )
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        recommendations = self._generate_recommendations(
            template["sections"],
            section_coverage,
            key_point_coverage,
            faq_count,
            template["min_faq_count"],
            priority_coverage
        )
        
        # ä¿å­˜è¯¦ç»†çš„è¦†ç›–ä¿¡æ¯ç”¨äºè°ƒè¯•
        self.stats["section_coverage"] = section_coverage
        self.stats["key_point_coverage"] = key_point_coverage
        
        return CompletenessCheckResult(
            document_type=document_type,
            total_sections=len(template["sections"]),
            covered_sections=section_coverage["covered_count"],
            section_coverage_rate=section_coverage["coverage_rate"],
            total_key_points=key_point_coverage["total_count"],
            covered_key_points=key_point_coverage["covered_count"],
            key_point_coverage_rate=key_point_coverage["coverage_rate"],
            faq_count=faq_count,
            min_faq_count_met=min_faq_count_met,
            priority_coverage=priority_coverage,
            overall_score=overall_score,
            recommendations=recommendations,
            covered_section_names=section_coverage.get("covered_sections", []),
            uncovered_section_names=section_coverage.get("uncovered_sections", [])
        )
    
    def _check_section_coverage(self, sections: List[Dict], faq_data: List[Dict], 
                               source_content: str) -> Dict[str, Any]:
        """æ£€æŸ¥ç« èŠ‚è¦†ç›–æƒ…å†µ"""
        covered_sections = []
        uncovered_sections = []
        
        for section in sections:
            section_name = section["name"]
            # æ£€æŸ¥FAQä¸­æ˜¯å¦æåŠè¯¥ç« èŠ‚
            section_mentioned = any(
                self._is_section_mentioned(section_name, faq.get("question", "")) or
                self._is_section_mentioned(section_name, faq.get("answer", ""))
                for faq in faq_data
            )
            
            # æ£€æŸ¥æºæ–‡æ¡£ä¸­æ˜¯å¦æœ‰ç›¸å…³å†…å®¹
            content_exists = self._is_section_mentioned(section_name, source_content)
            
            if section_mentioned and content_exists:
                covered_sections.append(section_name)
            elif content_exists:
                uncovered_sections.append(section_name)
        
        return {
            "covered_count": len(covered_sections),
            "uncovered_count": len(uncovered_sections),
            "coverage_rate": len(covered_sections) / len(sections) if sections else 0,
            "covered_sections": covered_sections,
            "uncovered_sections": uncovered_sections
        }
    
    def _check_key_point_coverage(self, sections: List[Dict], faq_data: List[Dict],
                                 source_content: str) -> Dict[str, Any]:
        """æ£€æŸ¥å…³é”®ç‚¹è¦†ç›–æƒ…å†µ"""
        total_key_points = 0
        covered_key_points = 0
        coverage_details = []
        
        for section in sections:
            for key_point in section.get("key_points", []):
                total_key_points += 1
                
                # æ£€æŸ¥FAQä¸­æ˜¯å¦æåŠè¯¥å…³é”®ç‚¹
                key_point_mentioned = any(
                    self._is_key_point_mentioned(key_point, faq.get("question", "")) or
                    self._is_key_point_mentioned(key_point, faq.get("answer", ""))
                    for faq in faq_data
                )
                
                # æ£€æŸ¥æºæ–‡æ¡£ä¸­æ˜¯å¦æœ‰ç›¸å…³å†…å®¹
                content_exists = self._is_key_point_mentioned(key_point, source_content)
                
                if key_point_mentioned and content_exists:
                    covered_key_points += 1
                    coverage_details.append({"key_point": key_point, "covered": True})
                elif content_exists:
                    coverage_details.append({"key_point": key_point, "covered": False})
        
        return {
            "total_count": total_key_points,
            "covered_count": covered_key_points,
            "coverage_rate": covered_key_points / total_key_points if total_key_points > 0 else 0,
            "details": coverage_details
        }
    
    def _check_priority_coverage(self, sections: List[Dict], 
                                section_coverage: Dict[str, Any]) -> Dict[str, bool]:
        """æ£€æŸ¥ä¼˜å…ˆçº§è¦†ç›–æƒ…å†µ"""
        priority_coverage = {"high": True, "medium": True, "low": True}
        
        for section in sections:
            priority = section.get("priority", "medium")
            section_name = section["name"]
            
            if section_name in section_coverage.get("uncovered_sections", []):
                if priority == "high":
                    priority_coverage["high"] = False
                elif priority == "medium":
                    priority_coverage["medium"] = False
        
        return priority_coverage
    
    def _is_section_mentioned(self, section_name: str, text: str) -> bool:
        """æ£€æŸ¥ç« èŠ‚æ˜¯å¦åœ¨æ–‡æœ¬ä¸­è¢«æåŠ"""
        if not text or not section_name:
            return False
        
        # ç®€åŒ–çš„åŒ¹é…é€»è¾‘ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„NLPæŠ€æœ¯
        keywords = section_name.replace("ã€", " ").replace("ï¼Œ", " ").replace("ï¼š", " ").split()
        keywords = [kw.strip() for kw in keywords if kw.strip()]
        
        if not keywords:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å…³é”®è¯åœ¨æ–‡æœ¬ä¸­å‡ºç°
        text_lower = text.lower()
        for keyword in keywords:
            if keyword.lower() in text_lower:
                return True
        return False
    
    def _is_section_content_covered(self, section: Dict, faq_data: List[Dict],
                                   source_content: str) -> bool:
        """æ·±åº¦æ£€æŸ¥ï¼šåˆ†æFAQå†…å®¹æ˜¯å¦æ¶‰åŠè¯¥ç« èŠ‚çš„çŸ¥è¯†ç‚¹"""
        section_name = section["name"]
        key_points = section.get("key_points", [])
        
        # è·å–è¯¥ç« èŠ‚åœ¨æºæ–‡æ¡£ä¸­çš„å†…å®¹
        section_content = self._extract_section_content(section_name, source_content)
        if not section_content:
            return False
        
        # åˆ†æè¯¥ç« èŠ‚çš„æ ¸å¿ƒæ¦‚å¿µå’Œå…³é”®è¯
        section_keywords = self._extract_section_keywords(section_name, section_content)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰FAQæ¶‰åŠè¿™äº›æ ¸å¿ƒæ¦‚å¿µ
        for faq in faq_data:
            faq_text = f"{faq.get('question', '')} {faq.get('answer', '')}"
            if self._has_concept_overlap(faq_text, section_keywords):
                return True
        
        return False
    
    def _extract_section_content(self, section_name: str, source_content: str) -> str:
        """ä»æºæ–‡æ¡£ä¸­æå–æŒ‡å®šç« èŠ‚çš„å†…å®¹"""
        # ç®€åŒ–çš„ç« èŠ‚æå–é€»è¾‘
        # å®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„æ–‡æœ¬åˆ†å‰²ç®—æ³•
        lines = source_content.split('\n')
        section_lines = []
        in_section = False
        
        for i, line in enumerate(lines):
            if section_name in line:
                in_section = True
                section_lines.append(line)
            elif in_section and i < len(lines) - 1:
                # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦æ˜¯æ–°çš„ç« èŠ‚å¼€å§‹
                next_line = lines[i + 1]
                if self._is_new_section_start(next_line):
                    break
                section_lines.append(line)
        
        return '\n'.join(section_lines)
    
    def _is_new_section_start(self, line: str) -> bool:
        """åˆ¤æ–­ä¸€è¡Œæ˜¯å¦æ˜¯æ–°ç« èŠ‚çš„å¼€å§‹"""
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç« èŠ‚æ ‡é¢˜æ¨¡å¼ï¼Œå¦‚ï¼š"ä¸€ã€" "äºŒã€" "ä¸‰ã€" æˆ– "1." "2." "3."
        patterns = [
            r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€',  # ä¸­æ–‡æ•°å­—ç« èŠ‚
            r'^\d+\.\d+\s',  # æ•°å­—ç« èŠ‚ï¼Œå¦‚ 3.1
            r'^[A-Z]\.',  # å­—æ¯ç« èŠ‚ï¼Œå¦‚ A.
            r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ç« ',  # "ç¬¬ä¸€ç« "æ ¼å¼
        ]
        
        for pattern in patterns:
            if re.match(pattern, line.strip()):
                return True
        return False
    
    def _extract_section_keywords(self, section_name: str, section_content: str) -> List[str]:
        """æå–ç« èŠ‚çš„æ ¸å¿ƒå…³é”®è¯"""
        keywords = []
        
        # æ·»åŠ ç« èŠ‚åç§°ä½œä¸ºå…³é”®è¯
        keywords.extend(section_name.replace("ã€", " ").split())
        
        # ä»å†…å®¹ä¸­æå–é«˜é¢‘è¯å’Œå…³é”®çŸ­è¯­
        words = re.findall(r'\b\w+\b', section_content.lower())
        # è¿‡æ»¤åœç”¨è¯
        stop_words = {'çš„', 'äº†', 'å’Œ', 'æ˜¯', 'åœ¨', 'æœ‰', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'ä»¬', 'è¿™', 'é‚£', 'ä¸ª', 'ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹', 'å'}
        meaningful_words = [word for word in words if word not in stop_words and len(word) > 1]
        
        # ç»Ÿè®¡è¯é¢‘ï¼Œå–å‰10ä¸ªé«˜é¢‘è¯
        from collections import Counter
        word_counts = Counter(meaningful_words)
        top_words = [word for word, count in word_counts.most_common(10)]
        
        keywords.extend(top_words)
        
        # å»é‡
        return list(set(keywords))
    
    def _has_concept_overlap(self, faq_text: str, section_keywords: List[str]) -> bool:
        """æ£€æŸ¥FAQæ–‡æœ¬æ˜¯å¦ä¸ç« èŠ‚å…³é”®è¯æœ‰æ¦‚å¿µé‡å """
        faq_text_lower = faq_text.lower()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å…³é”®è¯åœ¨FAQä¸­å‡ºç°
        for keyword in section_keywords:
            if keyword.lower() in faq_text_lower:
                return True
        
        # æ£€æŸ¥è¯­ä¹‰ç›¸ä¼¼æ€§ï¼ˆç®€åŒ–ç‰ˆï¼‰
        # å®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨è¯å‘é‡æˆ–é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹
        return False
    
    def _is_key_point_mentioned(self, key_point: str, text: str) -> bool:
        """æ£€æŸ¥å…³é”®ç‚¹æ˜¯å¦åœ¨æ–‡æœ¬ä¸­è¢«æåŠ"""
        if not text or not key_point:
            return False
        
        # æ‰©å±•åŒ¹é…é€»è¾‘ï¼šæ”¯æŒåŒä¹‰è¯å’Œè¿‘ä¹‰è¯
        key_point_variants = self._generate_key_point_variants(key_point)
        
        text_lower = text.lower()
        for variant in key_point_variants:
            if variant.lower() in text_lower:
                return True
        
        return False
    
    def _generate_key_point_variants(self, key_point: str) -> List[str]:
        """ç”Ÿæˆå…³é”®ç‚¹çš„å˜ä½“å½¢å¼ï¼ˆåŒä¹‰è¯ã€è¿‘ä¹‰è¯ï¼‰"""
        variants = [key_point]
        
        # æ·»åŠ å¸¸è§å˜ä½“
        if "è§£é™¤" in key_point:
            variants.extend(["è¾é€€", "ç»ˆæ­¢", "ç»“æŸ"])
        if "åˆåŒ" in key_point:
            variants.extend(["åè®®", "åˆçº¦"])
        if "æ¡ä»¶" in key_point:
            variants.extend(["è¦æ±‚", "æ ‡å‡†"])
        
        return list(set(variants))
    
    def get_detailed_stats(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats
    
    def _calculate_overall_score(self, section_coverage_rate: float,
                                key_point_coverage_rate: float,
                                faq_count: int,
                                min_faq_count: int,
                                priority_coverage: Dict[str, bool]) -> float:
        """è®¡ç®—æ€»ä½“å¾—åˆ†"""
        # å„ç»´åº¦æƒé‡
        weights = {
            "section_coverage": 0.3,
            "key_point_coverage": 0.4,
            "faq_count": 0.2,
            "priority_coverage": 0.1
        }
        
        # è®¡ç®—å„é¡¹å¾—åˆ†
        section_score = section_coverage_rate * weights["section_coverage"]
        
        key_point_score = key_point_coverage_rate * weights["key_point_coverage"]
        
        faq_count_score = (min(faq_count / min_faq_count, 1.0) * 
                          weights["faq_count"]) if min_faq_count > 0 else 0
        
        priority_score = (1.0 * weights["priority_coverage"] if priority_coverage.get("high") 
                         else 0.5 * weights["priority_coverage"])
        
        return section_score + key_point_score + faq_count_score + priority_score
    
    def _generate_recommendations(self, sections: List[Dict],
                                 section_coverage: Dict[str, Any],
                                 key_point_coverage: Dict[str, Any],
                                 faq_count: int,
                                 min_faq_count: int,
                                 priority_coverage: Dict[str, bool]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # æ£€æŸ¥ç« èŠ‚è¦†ç›–
        if section_coverage["coverage_rate"] < 0.8:
            recommendations.append(
                f"ç« èŠ‚è¦†ç›–ç‡ä»…ä¸º{section_coverage['coverage_rate']:.1%}ï¼Œå»ºè®®å¢åŠ ä»¥ä¸‹ç« èŠ‚çš„FAQ: "
                f"{', '.join(section_coverage['uncovered_sections'][:3])}"
            )
        
        # æ£€æŸ¥å…³é”®ç‚¹è¦†ç›–
        if key_point_coverage["coverage_rate"] < 0.85:
            uncovered_points = [d["key_point"] for d in key_point_coverage["details"] if not d["covered"]]
            recommendations.append(
                f"å…³é”®ç‚¹è¦†ç›–ç‡ä¸º{key_point_coverage['coverage_rate']:.1%}ï¼Œå»ºè®®è¡¥å……ä»¥ä¸‹å…³é”®ç‚¹: "
                f"{', '.join(uncovered_points[:5])}"
            )
        
        # æ£€æŸ¥FAQæ•°é‡
        if faq_count < min_faq_count:
            recommendations.append(
                f"FAQæ•°é‡ä¸è¶³ï¼Œå½“å‰{faq_count}ä¸ªï¼Œå»ºè®®è‡³å°‘{min_faq_count}ä¸ª"
            )
        
        # æ£€æŸ¥é«˜ä¼˜å…ˆçº§è¦†ç›–
        if not priority_coverage.get("high"):
            recommendations.append(
                "å­˜åœ¨é«˜ä¼˜å…ˆçº§ç« èŠ‚æœªè¦†ç›–ï¼Œè¯·ä¼˜å…ˆè¡¥å……è¿™äº›ç« èŠ‚çš„FAQ"
            )
        
        return recommendations


def parse_faq_file(faq_file_path: str) -> List[Dict[str, str]]:
    """
    è§£æFAQ Markdownæ–‡ä»¶ï¼Œæå–é—®ç­”å¯¹
    
    Args:
        faq_file_path: FAQæ–‡ä»¶è·¯å¾„
        
    Returns:
        FAQæ•°æ®åˆ—è¡¨
    """
    if not os.path.exists(faq_file_path):
        logger.error(f"FAQæ–‡ä»¶ä¸å­˜åœ¨: {faq_file_path}")
        return []
    
    try:
        with open(faq_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        if not content:
            logger.warning(f"FAQæ–‡ä»¶ä¸ºç©º: {faq_file_path}")
            return []
        
        faq_data = []
        # åŒ¹é…FAQæ ¼å¼ï¼š### Qxx: é—®é¢˜æ ‡é¢˜
        faq_pattern = r'### Q\d+:\s*(.+?)\n\*\*A:\*\*\s*(.+?)(?=\n\n### Q|\n\n---|\Z)'
        matches = re.findall(faq_pattern, content, re.DOTALL)
        
        logger.info(f"ä»FAQæ–‡ä»¶ä¸­æå–åˆ° {len(matches)} ä¸ªé—®ç­”å¯¹")
        
        for question, answer in matches:
            # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
            question = question.strip()
            answer = answer.strip()
            if question and answer:  # ç¡®ä¿é—®é¢˜å’Œç­”æ¡ˆéƒ½ä¸ä¸ºç©º
                faq_data.append({
                    "question": question,
                    "answer": answer
                })
        
        if not faq_data:
            logger.warning(f"æœªèƒ½ä»æ–‡ä»¶ä¸­æå–ä»»ä½•FAQ: {faq_file_path}")
            logger.info("è¯·ç¡®ä¿FAQæ ¼å¼æ­£ç¡®ï¼š### Q1: é—®é¢˜æ ‡é¢˜\\n**A:** ç­”æ¡ˆå†…å®¹")
        
        return faq_data
    except UnicodeDecodeError:
        logger.error(f"æ–‡ä»¶ç¼–ç é—®é¢˜ï¼Œè¯·ç¡®ä¿æ–‡ä»¶ä¸ºUTF-8ç¼–ç : {faq_file_path}")
        return []
    except Exception as e:
        logger.error(f"è¯»å–FAQæ–‡ä»¶å¤±è´¥: {e}")
        return []


def parse_pdf_file(pdf_file_path: str) -> str:
    """
    è§£æPDFæ–‡ä»¶ï¼Œæå–æ–‡æœ¬å†…å®¹
    
    Args:
        pdf_file_path: PDFæ–‡ä»¶è·¯å¾„
        
    Returns:
        PDFæ–‡æœ¬å†…å®¹
    """
    if not PDF_SUPPORT:
        logger.error("PyPDF2æœªå®‰è£…ï¼Œæ— æ³•è¯»å–PDFæ–‡ä»¶ã€‚è¯·è¿è¡Œ: pip install PyPDF2")
        return ""
    
    try:
        with open(pdf_file_path, 'rb') as f:
            pdf_reader = PyPDF2.PdfReader(f)
            text_content = []
            
            logger.info(f"PDFæ–‡ä»¶å…±æœ‰ {len(pdf_reader.pages)} é¡µ")
            
            for page_num, page in enumerate(pdf_reader.pages):
                try:
                    page_text = page.extract_text()
                    if page_text:
                        text_content.append(page_text)
                    else:
                        logger.warning(f"ç¬¬ {page_num + 1} é¡µæœªèƒ½æå–æ–‡æœ¬")
                except Exception as e:
                    logger.warning(f"æå–ç¬¬ {page_num + 1} é¡µæ–‡æœ¬æ—¶å‡ºé”™: {e}")
            
            full_text = "\n".join(text_content)
            logger.info(f"æˆåŠŸæå– {len(full_text)} ä¸ªå­—ç¬¦")
            return full_text
    
    except Exception as e:
        logger.error(f"è¯»å–PDFæ–‡ä»¶å¤±è´¥: {e}")
        return ""


def parse_source_file(source_file_path: str) -> str:
    """
    è§£ææºæ–‡æ¡£æ–‡ä»¶ï¼ˆæ”¯æŒPDFå’Œæ–‡æœ¬æ ¼å¼ï¼‰
    
    Args:
        source_file_path: æºæ–‡æ¡£è·¯å¾„
        
    Returns:
        æºæ–‡æ¡£å†…å®¹
    """
    if not os.path.exists(source_file_path):
        logger.error(f"æºæ–‡æ¡£ä¸å­˜åœ¨: {source_file_path}")
        return ""
    
    # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è§£ææ–¹å¼
    file_ext = os.path.splitext(source_file_path)[1].lower()
    
    if file_ext == '.pdf':
        logger.info(f"æ£€æµ‹åˆ°PDFæ–‡ä»¶ï¼Œä½¿ç”¨PDFè§£æå™¨: {source_file_path}")
        return parse_pdf_file(source_file_path)
    else:
        # é»˜è®¤ä¸ºæ–‡æœ¬æ–‡ä»¶
        try:
            with open(source_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if not content:
                logger.warning(f"æºæ–‡æ¡£ä¸ºç©º: {source_file_path}")
            
            logger.info(f"æˆåŠŸè¯»å–æºæ–‡æ¡£ï¼Œå…± {len(content)} ä¸ªå­—ç¬¦")
            return content
        except UnicodeDecodeError:
            logger.error(f"æ–‡ä»¶ç¼–ç é—®é¢˜ï¼Œè¯·ç¡®ä¿æ–‡ä»¶ä¸ºUTF-8ç¼–ç : {source_file_path}")
            return ""
        except Exception as e:
            logger.error(f"è¯»å–æºæ–‡æ¡£å¤±è´¥: {e}")
            return ""


def main():
    """ä¸»å‡½æ•°ï¼šå‘½ä»¤è¡Œç”¨æ³•"""
    parser = argparse.ArgumentParser(
        description='FAQå®Œæ•´æ€§æ£€æŸ¥å·¥å…· - éªŒè¯ç”Ÿæˆçš„FAQæ˜¯å¦å®Œæ•´è¦†ç›–æºæ–‡æ¡£çš„å…³é”®å†…å®¹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æ£€æŸ¥å‘˜å·¥æ‰‹å†ŒFAQå®Œæ•´æ€§
  python faq_completeness_checklist.py å‘˜å·¥æ‰‹å†ŒFAQ.md å‘˜å·¥æ‰‹å†Œ.pdf --type employee_handbook
  
  # æ£€æŸ¥æ”¿ç­–æ–‡æ¡£FAQå®Œæ•´æ€§
  python faq_completeness_checklist.py æ”¿ç­–FAQ.md æ”¿ç­–æ–‡æ¡£.pdf --type policy_document
  
  # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯å’Œè°ƒè¯•æ—¥å¿—
  python faq_completeness_checklist.py å‘˜å·¥æ‰‹å†ŒFAQ.md å‘˜å·¥æ‰‹å†Œ.pdf --type employee_handbook --verbose
  
  # æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
  python faq_completeness_checklist.py --help
        
ä¾èµ–è¯´æ˜:
  - æ”¯æŒMarkdownæ ¼å¼çš„FAQæ–‡ä»¶
  - æ”¯æŒPDFå’Œæ–‡æœ¬æ ¼å¼çš„æºæ–‡æ¡£
  - å¦‚éœ€PDFæ”¯æŒï¼Œè¯·å®‰è£…: pip install PyPDF2
        """
    )
    
    parser.add_argument('faq_file', help='FAQæ–‡ä»¶è·¯å¾„ï¼ˆMarkdownæ ¼å¼ï¼‰')
    parser.add_argument('source_file', help='æºæ–‡æ¡£è·¯å¾„ï¼ˆPDFæˆ–æ–‡æœ¬æ ¼å¼ï¼‰')
    parser.add_argument('--type', default='employee_handbook',
                       choices=['employee_handbook', 'policy_document', 'operation_guide', 'product_manual'],
                       help='æ–‡æ¡£ç±»å‹ï¼ˆå†³å®šæ£€æŸ¥æ ‡å‡†å’Œæœ€ä½FAQæ•°é‡ï¼‰')
    parser.add_argument('--verbose', '-v', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†æ£€æŸ¥ä¿¡æ¯å’Œè°ƒè¯•æ—¥å¿—')
    parser.add_argument('--debug', '-d', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆæ˜¾ç¤ºæ›´å¤šæŠ€æœ¯ç»†èŠ‚ï¼‰')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    elif args.verbose:
        logging.getLogger().setLevel(logging.INFO)
    else:
        logging.getLogger().setLevel(logging.WARNING)
    
    logger.info("=" * 70)
    logger.info("FAQå®Œæ•´æ€§æ£€æŸ¥å·¥å…·å¯åŠ¨")
    logger.info("=" * 70)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.isfile(args.faq_file):
        logger.error(f"FAQæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯æ–‡ä»¶: {args.faq_file}")
        print(f"âŒ é”™è¯¯ï¼šFAQæ–‡ä»¶ä¸å­˜åœ¨: {args.faq_file}", file=sys.stderr)
        sys.exit(1)
    
    if not os.path.isfile(args.source_file):
        logger.error(f"æºæ–‡æ¡£ä¸å­˜åœ¨æˆ–ä¸æ˜¯æ–‡ä»¶: {args.source_file}")
        print(f"âŒ é”™è¯¯ï¼šæºæ–‡æ¡£ä¸å­˜åœ¨: {args.source_file}", file=sys.stderr)
        sys.exit(1)
    
    logger.info(f"FAQæ–‡ä»¶: {args.faq_file}")
    logger.info(f"æºæ–‡æ¡£: {args.source_file}")
    logger.info(f"æ–‡æ¡£ç±»å‹: {args.type}")
    
    # è§£ææ–‡ä»¶
    logger.info("å¼€å§‹è§£æFAQæ–‡ä»¶...")
    faq_data = parse_faq_file(args.faq_file)
    
    logger.info("å¼€å§‹è§£ææºæ–‡æ¡£...")
    source_content = parse_source_file(args.source_file)
    
    if not faq_data:
        logger.error("æœªèƒ½è¯»å–æœ‰æ•ˆçš„FAQæ•°æ®")
        print("âŒ é”™è¯¯ï¼šæœªèƒ½è¯»å–æœ‰æ•ˆçš„FAQæ•°æ®", file=sys.stderr)
        sys.exit(1)
    
    if not source_content:
        logger.error("æœªèƒ½è¯»å–æœ‰æ•ˆçš„æºæ–‡æ¡£å†…å®¹")
        print("âŒ é”™è¯¯ï¼šæœªèƒ½è¯»å–æœ‰æ•ˆçš„æºæ–‡æ¡£å†…å®¹", file=sys.stderr)
        sys.exit(1)
    
    logger.info(f"æˆåŠŸæå– {len(faq_data)} ä¸ªFAQé—®ç­”å¯¹")
    logger.info(f"æºæ–‡æ¡£å†…å®¹é•¿åº¦: {len(source_content)} å­—ç¬¦")
    
    # æ‰§è¡Œå®Œæ•´æ€§æ£€æŸ¥
    logger.info("å¼€å§‹æ‰§è¡Œå®Œæ•´æ€§æ£€æŸ¥...")
    checker = FAQCompletenessChecker()
    result = checker.check_completeness(
        document_type=args.type,
        faq_data=faq_data,
        source_content=source_content
    )
    
    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 70)
    print(" " * 20 + "FAQå®Œæ•´æ€§æ£€æŸ¥ç»“æœ")
    print("=" * 70)
    print(f"ğŸ“„ æ–‡æ¡£ç±»å‹: {result.document_type}")
    print(f"ğŸ“Š æ€»ä½“å¾—åˆ†: {result.overall_score:.2f}/1.00")
    print(f"ğŸ“š ç« èŠ‚è¦†ç›–ç‡: {result.section_coverage_rate:.1%} ({result.covered_sections}/{result.total_sections})")
    print(f"ğŸ¯ å…³é”®ç‚¹è¦†ç›–ç‡: {result.key_point_coverage_rate:.1%} ({result.covered_key_points}/{result.total_key_points})")
    print(f"â“ FAQæ•°é‡: {result.faq_count}ä¸ª")
    
    min_faq = 30 if args.type == 'employee_handbook' else 15
    print(f"ğŸ“ˆ æœ€ä½è¦æ±‚: {min_faq}ä¸ª")
    
    # çŠ¶æ€æŒ‡ç¤º
    status_emoji = "âœ…" if result.overall_score >= 0.7 and result.priority_coverage['high'] else "âš ï¸" if result.overall_score >= 0.5 else "âŒ"
    print(f"{status_emoji} æ•°é‡è¾¾æ ‡: {'æ˜¯' if result.min_faq_count_met else 'å¦'}")
    print(f"{status_emoji} é«˜ä¼˜å…ˆçº§è¦†ç›–: {'æ˜¯' if result.priority_coverage['high'] else 'å¦'}")
    
    print("-" * 70)
    
    if result.recommendations:
        print("ğŸ’¡ æ”¹è¿›å»ºè®®:")
        for i, rec in enumerate(result.recommendations, 1):
            print(f"   {i}. {rec}")
    else:
        print("ğŸ‰ æ­å–œï¼FAQå®Œæ•´æ€§æ£€æŸ¥é€šè¿‡ï¼Œæ— éœ€æ”¹è¿›ã€‚")
    
    # è¯¦ç»†æ¨¡å¼
    if args.verbose or args.debug:
        print("\n" + "-" * 70)
        print("ğŸ“‹ è¯¦ç»†ä¿¡æ¯:")
        print(f"   å·²è¦†ç›–ç« èŠ‚: {', '.join(result.covered_section_names) if result.covered_section_names else 'æ— '}")
        print(f"   æœªè¦†ç›–ç« èŠ‚: {', '.join(result.uncovered_section_names) if result.uncovered_section_names else 'æ— '}")
    
    print("=" * 70 + "\n")
    
    # è¿”å›ç 
    success = result.overall_score >= 0.7 and result.priority_coverage['high']
    if success:
        logger.info("å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡ï¼")
        print("\nğŸ‰ æ­å–œï¼FAQå®Œæ•´æ€§æ£€æŸ¥é€šè¿‡ï¼Œè¾¾åˆ°ç”Ÿäº§çº§æ ‡å‡†ã€‚")
    else:
        logger.warning("å®Œæ•´æ€§æ£€æŸ¥æœªé€šè¿‡ï¼Œéœ€è¦æ”¹è¿›")
        print("\nâš ï¸  æ³¨æ„ï¼šFAQå®Œæ•´æ€§æ£€æŸ¥æœªé€šè¿‡ï¼Œå»ºè®®è¡¥å……ç¼ºå¤±å†…å®¹ã€‚")
    
    # è¾“å‡ºJSONæ ¼å¼çš„è¯¦ç»†ç»“æœï¼Œä¾¿äºå…¶ä»–ç¨‹åºè§£æ
    if args.debug:
        import json
        result_dict = {
            "document_type": result.document_type,
            "overall_score": round(result.overall_score, 2),
            "section_coverage_rate": round(result.section_coverage_rate, 2),
            "key_point_coverage_rate": round(result.key_point_coverage_rate, 2),
            "faq_count": result.faq_count,
            "min_faq_count_met": result.min_faq_count_met,
            "priority_coverage_high": result.priority_coverage['high'],
            "covered_sections": result.covered_section_names,
            "uncovered_sections": result.uncovered_section_names,
            "recommendations": result.recommendations,
            "passed": success
        }
        print(f"\nğŸ“Š JSONç»“æœ:\n{json.dumps(result_dict, ensure_ascii=False, indent=2)}")
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()