#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†æ ¼å¼è§„èŒƒåŒ–å™¨
ç»Ÿä¸€æœ¯è¯­å’Œè¡¨è¾¾æ–¹å¼ï¼Œä¼˜åŒ–å†…å®¹ç»“æ„ï¼Œç¡®ä¿çŸ¥è¯†æ ¼å¼çš„ä¸€è‡´æ€§å’Œè§„èŒƒæ€§
"""

import re
import json
import sys
from pathlib import Path
from typing import Dict, List, Any, Tuple


class KnowledgeFormatNormalizer:
    """çŸ¥è¯†æ ¼å¼è§„èŒƒåŒ–å™¨ç±»"""
    
    def __init__(self, format_standards: Dict[str, Any] = None):
        self.format_standards = format_standards or self._load_default_standards()
        self.changes = []
        
    def _load_default_standards(self) -> Dict[str, Any]:
        """åŠ è½½é»˜è®¤æ ¼å¼æ ‡å‡†"""
        return {
            "terminology": {
                "å¹´å‡": "å¹´åº¦ä¼‘å‡",
                "è¯·å‡": "ç”³è¯·ä¼‘å‡",
                "ä¸»ç®¡": "ç›´æ¥ä¸»ç®¡",
                "ç»ç†": "éƒ¨é—¨ç»ç†",
                "æå®š": "å®Œæˆ",
                "å¼„å¥½": "å®Œæˆ"
            },
            "document_structure": {
                "title_format": r"^#+\s+.+$",
                "list_format": r"^[-*+]\s+.+$",
                "numbered_list_format": r"^\d+\.\s+.+$"
            },
            "expression_patterns": {
                "passive_to_active": {
                    "è¢«æ‰¹å‡†": "è·å¾—æ‰¹å‡†",
                    "è¢«è¦æ±‚": "éœ€è¦",
                    "è¢«é€šçŸ¥": "æ”¶åˆ°é€šçŸ¥"
                }
            }
        }
    
    def normalize_content(self, content: str) -> Tuple[str, List[Dict]]:
        """è§„èŒƒåŒ–å†…å®¹"""
        self.changes = []
        normalized = content
        
        # 1. æœ¯è¯­ç»Ÿä¸€
        normalized = self._normalize_terminology(normalized)
        
        # 2. ç»“æ„ä¼˜åŒ–
        normalized = self._optimize_structure(normalized)
        
        # 3. è¡¨è¾¾ä¼˜åŒ–
        normalized = self._optimize_expressions(normalized)
        
        return normalized, self.changes
    
    def _normalize_terminology(self, content: str) -> str:
        """ç»Ÿä¸€æœ¯è¯­"""
        terminology = self.format_standards.get("terminology", {})
        
        for old_term, new_term in terminology.items():
            if old_term in content:
                content = content.replace(old_term, new_term)
                self.changes.append({
                    "change_type": "terminology",
                    "original": old_term,
                    "normalized": new_term,
                    "location": "content"
                })
        
        return content
    
    def _optimize_structure(self, content: str) -> str:
        """ä¼˜åŒ–æ–‡æ¡£ç»“æ„"""
        lines = content.split('\n')
        optimized_lines = []
        
        for i, line in enumerate(lines):
            original_line = line
            
            # ä¼˜åŒ–æ ‡é¢˜æ ¼å¼
            if line.strip().startswith('#'):
                line = self._optimize_title(line)
            
            # ä¼˜åŒ–åˆ—è¡¨æ ¼å¼
            if re.match(r'^\s*[-*+]\s+', line):
                line = self._optimize_list_item(line)
            
            # ä¼˜åŒ–ç¼–å·åˆ—è¡¨
            if re.match(r'^\s*\d+\.\s+', line):
                line = self._optimize_numbered_list(line)
            
            if line != original_line:
                self.changes.append({
                    "change_type": "structure",
                    "original": original_line,
                    "normalized": line,
                    "line_number": i + 1
                })
            
            optimized_lines.append(line)
        
        return '\n'.join(optimized_lines)
    
    def _optimize_title(self, title: str) -> str:
        """ä¼˜åŒ–æ ‡é¢˜æ ¼å¼"""
        # ç¡®ä¿æ ‡é¢˜å±‚çº§æ­£ç¡®
        title = title.strip()
        
        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
        title = re.sub(r'^(#+)\s+', r'\1 ', title)
        
        # ç¡®ä¿æ ‡é¢˜æœ«å°¾æ²¡æœ‰æ ‡ç‚¹ç¬¦å·
        title = re.sub(r'([ã€‚ï¼ï¼Ÿ,;:!?])$', '', title)
        
        return title
    
    def _optimize_list_item(self, item: str) -> str:
        """ä¼˜åŒ–åˆ—è¡¨é¡¹æ ¼å¼"""
        # ç»Ÿä¸€ä½¿ç”¨ '-' ä½œä¸ºåˆ—è¡¨ç¬¦å·
        item = re.sub(r'^\s*[*+]\s+', '- ', item)
        
        # ç¡®ä¿åˆ—è¡¨é¡¹é¦–å­—æ¯å¤§å†™
        match = re.match(r'^(\s*-\s+)(.+)$', item)
        if match:
            prefix = match.group(1)
            content = match.group(2)
            if content and content[0].islower():
                content = content[0].upper() + content[1:]
            item = prefix + content
        
        return item
    
    def _optimize_numbered_list(self, item: str) -> str:
        """ä¼˜åŒ–ç¼–å·åˆ—è¡¨æ ¼å¼"""
        # ç¡®ä¿ç¼–å·åæœ‰ä¸€ä¸ªç©ºæ ¼
        item = re.sub(r'^(\s*\d+)\.\s+', r'\1. ', item)
        
        # ç¡®ä¿é¦–å­—æ¯å¤§å†™
        match = re.match(r'^(\s*\d+\.\s+)(.+)$', item)
        if match:
            prefix = match.group(1)
            content = match.group(2)
            if content and content[0].islower():
                content = content[0].upper() + content[1:]
            item = prefix + content
        
        return item
    
    def _optimize_expressions(self, content: str) -> str:
        """ä¼˜åŒ–è¡¨è¾¾æ–¹å¼"""
        expression_patterns = self.format_standards.get("expression_patterns", {})
        
        for pattern_type, patterns in expression_patterns.items():
            if pattern_type == "passive_to_active":
                for passive, active in patterns.items():
                    if passive in content:
                        content = content.replace(passive, active)
                        self.changes.append({
                            "change_type": "expression",
                            "original": passive,
                            "normalized": active,
                            "pattern_type": pattern_type
                        })
        
        return content
    
    def generate_report(self, original: str, normalized: str, changes: List[Dict]) -> Dict[str, Any]:
        """ç”Ÿæˆè§„èŒƒåŒ–æŠ¥å‘Š"""
        # ç»Ÿè®¡å˜æ›´ç±»å‹
        change_stats = {}
        for change in changes:
            change_type = change["change_type"]
            change_stats[change_type] = change_stats.get(change_type, 0) + 1
        
        # è®¡ç®—ä¸€è‡´æ€§è¯„åˆ†
        total_changes = len(changes)
        content_length = len(original)
        consistency_score = max(0, 1 - (total_changes / max(content_length / 100, 1)))
        
        # è®¡ç®—æœ¯è¯­ç»Ÿä¸€æ€§
        terminology_changes = change_stats.get("terminology", 0)
        terminology_score = 1 - (terminology_changes / max(total_changes, 1) * 0.5)
        
        return {
            "normalization_summary": {
                "consistency_score": round(consistency_score, 2),
                "terminology_score": round(terminology_score, 2),
                "total_changes": total_changes
            },
            "change_statistics": change_stats,
            "detailed_changes": changes,
            "improvement_recommendations": self._generate_recommendations(change_stats)
        }
    
    def _generate_recommendations(self, change_stats: Dict[str, int]) -> List[Dict]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        terminology_changes = change_stats.get("terminology", 0)
        structure_changes = change_stats.get("structure", 0)
        expression_changes = change_stats.get("expression", 0)
        
        if terminology_changes > 5:
            recommendations.append({
                "priority": "high",
                "recommendation": f"ç»Ÿä¸€äº† {terminology_changes} ä¸ªæœ¯è¯­ï¼Œå»ºè®®å»ºç«‹æœ¯è¯­è¯å…¸",
                "estimated_effort": "2å°æ—¶"
            })
        
        if structure_changes > 3:
            recommendations.append({
                "priority": "medium",
                "recommendation": f"ä¼˜åŒ–äº† {structure_changes} å¤„æ–‡æ¡£ç»“æ„",
                "estimated_effort": "1å°æ—¶"
            })
        
        if expression_changes > 2:
            recommendations.append({
                "priority": "low",
                "recommendation": f"æ”¹è¿›äº† {expression_changes} å¤„è¡¨è¾¾æ–¹å¼",
                "estimated_effort": "0.5å°æ—¶"
            })
        
        if not recommendations:
            recommendations.append({
                "priority": "low",
                "recommendation": "æ ¼å¼è§„èŒƒæ€§è‰¯å¥½ï¼Œå»ºè®®å®šæœŸæ£€æŸ¥å’Œç»´æŠ¤",
                "estimated_effort": "0.5å°æ—¶/æœˆ"
            })
        
        return recommendations


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python format_normalizer.py <çŸ¥è¯†å†…å®¹æ–‡ä»¶è·¯å¾„>")
        sys.exit(1)
    
    content_file = sys.argv[1]
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(content_file).exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {content_file}")
        sys.exit(1)
    
    # è¯»å–å†…å®¹
    try:
        with open(content_file, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)
    
    # åˆ›å»ºè§„èŒƒåŒ–å™¨å¹¶æ‰§è¡Œè§„èŒƒåŒ–
    normalizer = KnowledgeFormatNormalizer()
    normalized_content, changes = normalizer.normalize_content(content)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = normalizer.generate_report(content, normalized_content, changes)
    
    # æ‰“å°æŠ¥å‘Š
    print("\n" + "="*60)
    print("çŸ¥è¯†æ ¼å¼è§„èŒƒåŒ–æŠ¥å‘Š")
    print("="*60)
    
    summary = report["normalization_summary"]
    print(f"\nğŸ“Š ä¸€è‡´æ€§è¯„åˆ†: {summary['consistency_score']}/1.0")
    print(f"ğŸ“Š æœ¯è¯­ç»Ÿä¸€æ€§: {summary['terminology_score']}/1.0")
    print(f"ğŸ“‹ æ€»å˜æ›´æ•°: {summary['total_changes']}")
    
    print("\nğŸ“ˆ å˜æ›´ç»Ÿè®¡:")
    for change_type, count in report["change_statistics"].items():
        print(f"  â€¢ {change_type}: {count}")
    
    if changes:
        print(f"\nğŸ” è¯¦ç»†å˜æ›´ ({len(changes)}ä¸ª):")
        for i, change in enumerate(changes[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            if change["change_type"] == "terminology":
                print(f"{i}. æœ¯è¯­ç»Ÿä¸€: {change['original']} â†’ {change['normalized']}")
            elif change["change_type"] == "structure":
                print(f"{i}. ç»“æ„ä¼˜åŒ–: {change['original'][:30]}...")
            elif change["change_type"] == "expression":
                print(f"{i}. è¡¨è¾¾ä¼˜åŒ–: {change['original']} â†’ {change['normalized']}")
    
    print("\nğŸ’¡ æ”¹è¿›å»ºè®®:")
    for i, rec in enumerate(report["improvement_recommendations"], 1):
        print(f"{i}. [{rec['priority']}] {rec['recommendation']}")
        print(f"   é¢„è®¡å·¥ä½œé‡: {rec['estimated_effort']}")
    
    # ä¿å­˜è§„èŒƒåŒ–åçš„å†…å®¹
    output_file = "normalized_content.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(normalized_content)
    
    print(f"\nğŸ“„ è§„èŒƒåŒ–åçš„å†…å®¹å·²ä¿å­˜åˆ°: {output_file}")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_file = "format_normalization_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“Š è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


if __name__ == "__main__":
    main()