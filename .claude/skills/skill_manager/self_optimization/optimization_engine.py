#!/usr/bin/env python3
"""
Skillè‡ªä¼˜åŒ–å¼•æ“
åŸºäºç”¨æˆ·è¡Œä¸ºæ•°æ®å’Œæ€§èƒ½æŒ‡æ ‡ï¼Œè‡ªåŠ¨ä¼˜åŒ–ç°æœ‰Skill
"""

import os
import sys
import json
import yaml
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field

# æ·»åŠ è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from models import OperationRecord


@dataclass
class SkillPerformanceMetrics:
    """Skillæ€§èƒ½æŒ‡æ ‡"""
    skill_name: str
    period_start: datetime
    period_end: datetime
    
    # ä½¿ç”¨æŒ‡æ ‡
    total_calls: int = 0
    success_calls: int = 0
    failed_calls: int = 0
    avg_duration: float = 0.0
    total_duration: float = 0.0
    
    # è´¨é‡æŒ‡æ ‡
    user_satisfaction: float = 0.0  # 1-5åˆ†
    satisfaction_count: int = 0
    error_rate: float = 0.0
    timeout_rate: float = 0.0
    
    # ä»·å€¼æŒ‡æ ‡
    time_saved: float = 0.0  # åˆ†é’Ÿ
    user_adoption_rate: float = 0.0  # é‡‡ç”¨ç‡
    
    # å¥åº·åº¦
    health_score: float = 0.0  # 0-100åˆ†
    
    def calculate_health_score(self) -> float:
        """è®¡ç®—å¥åº·åº¦åˆ†æ•°"""
        if self.total_calls == 0:
            return 0.0
        
        # æˆåŠŸç‡æƒé‡ 40%
        success_rate = self.success_calls / self.total_calls if self.total_calls > 0 else 0
        success_score = success_rate * 40
        
        # ç”¨æˆ·æ»¡æ„åº¦æƒé‡ 30%
        satisfaction_score = (self.user_satisfaction / 5.0) * 30 if self.user_satisfaction > 0 else 0
        
        # é‡‡ç”¨ç‡æƒé‡ 20%
        adoption_score = self.user_adoption_rate * 20
        
        # æ€§èƒ½æƒé‡ 10%
        performance_score = max(0, 10 - (self.avg_duration / 10))  # å‡è®¾10ç§’ä¸ºæ»¡åˆ†
        
        self.health_score = success_score + satisfaction_score + adoption_score + performance_score
        return self.health_score
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'skill_name': self.skill_name,
            'period_start': self.period_start.isoformat(),
            'period_end': self.period_end.isoformat(),
            'total_calls': self.total_calls,
            'success_calls': self.success_calls,
            'failed_calls': self.failed_calls,
            'avg_duration': self.avg_duration,
            'total_duration': self.total_duration,
            'user_satisfaction': self.user_satisfaction,
            'satisfaction_count': self.satisfaction_count,
            'error_rate': self.error_rate,
            'timeout_rate': self.timeout_rate,
            'time_saved': self.time_saved,
            'user_adoption_rate': self.user_adoption_rate,
            'health_score': self.health_score
        }


@dataclass
class OptimizationRecommendation:
    """ä¼˜åŒ–å»ºè®®"""
    skill_name: str
    recommendation_type: str  # parameter, template, documentation, enhancement
    priority: str  # high, medium, low
    description: str
    expected_impact: str
    implementation_effort: str  # low, medium, high
    specific_actions: List[str] = field(default_factory=list)
    current_metrics: Optional[Dict[str, Any]] = None
    target_metrics: Optional[Dict[str, Any]] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'skill_name': self.skill_name,
            'recommendation_type': self.recommendation_type,
            'priority': self.priority,
            'description': self.description,
            'expected_impact': self.expected_impact,
            'implementation_effort': self.implementation_effort,
            'specific_actions': self.specific_actions,
            'current_metrics': self.current_metrics,
            'target_metrics': self.target_metrics
        }


class SkillPerformanceTracker:
    """Skillæ€§èƒ½è¿½è¸ªå™¨"""
    
    def __init__(self, data_dir: Optional[Path] = None):
        self.data_dir = data_dir or Path(__file__).parent / 'data'
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.metrics_file = self.data_dir / 'skill_metrics.json'
        self.usage_log_file = self.data_dir / 'skill_usage.log'
    
    def record_skill_usage(self, skill_name: str, operation: OperationRecord, 
                          user_satisfaction: Optional[int] = None):
        """è®°å½•Skillä½¿ç”¨"""
        usage_data = {
            'timestamp': datetime.now().isoformat(),
            'skill_name': skill_name,
            'operation': operation.to_dict(),
            'user_satisfaction': user_satisfaction,
            'success': operation.is_successful()
        }
        
        try:
            with open(self.usage_log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(usage_data, ensure_ascii=False) + '\n')
        except Exception as e:
            print(f"è®°å½•Skillä½¿ç”¨å¤±è´¥: {e}")
    
    def collect_metrics(self, skill_name: Optional[str] = None, 
                       days: int = 30) -> List[SkillPerformanceMetrics]:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        if not self.usage_log_file.exists():
            return []
        
        cutoff_time = datetime.now() - timedelta(days=days)
        skill_metrics = {}
        
        try:
            with open(self.usage_log_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        usage_data = json.loads(line)
                        op_time = datetime.fromisoformat(usage_data['timestamp'])
                        
                        if op_time < cutoff_time:
                            continue
                        
                        name = usage_data['skill_name']
                        if skill_name and name != skill_name:
                            continue
                        
                        if name not in skill_metrics:
                            skill_metrics[name] = SkillPerformanceMetrics(
                                skill_name=name,
                                period_start=cutoff_time,
                                period_end=datetime.now()
                            )
                        
                        self._update_metrics(skill_metrics[name], usage_data)
                        
                    except (json.JSONDecodeError, KeyError, ValueError):
                        continue
        
        except Exception as e:
            print(f"æ”¶é›†æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
        
        # è®¡ç®—å¥åº·åº¦
        for metrics in skill_metrics.values():
            metrics.calculate_health_score()
        
        return list(skill_metrics.values())
    
    def _update_metrics(self, metrics: SkillPerformanceMetrics, usage_data: Dict[str, Any]):
        """æ›´æ–°æŒ‡æ ‡"""
        metrics.total_calls += 1
        
        if usage_data.get('success', False):
            metrics.success_calls += 1
        else:
            metrics.failed_calls += 1
        
        operation = usage_data.get('operation', {})
        duration = operation.get('duration_seconds', 0)
        metrics.total_duration += duration
        
        satisfaction = usage_data.get('user_satisfaction')
        if satisfaction:
            metrics.satisfaction_count += 1
            # è®¡ç®—ç§»åŠ¨å¹³å‡
            total_satisfaction = metrics.user_satisfaction * (metrics.satisfaction_count - 1) + satisfaction
            metrics.user_satisfaction = total_satisfaction / metrics.satisfaction_count
        
        # è®¡ç®—å¹³å‡æ—¶é•¿
        if metrics.total_calls > 0:
            metrics.avg_duration = metrics.total_duration / metrics.total_calls
        
        # è®¡ç®—é”™è¯¯ç‡
        metrics.error_rate = metrics.failed_calls / metrics.total_calls
        
        # ä¼°ç®—èŠ‚çœæ—¶é—´ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
        metrics.time_saved = metrics.success_calls * 5  # å‡è®¾æ¯æ¬¡æˆåŠŸèŠ‚çœ5åˆ†é’Ÿ


class SkillDeviationDetector:
    """Skillåå·®æ£€æµ‹å™¨"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.thresholds = self.config.get('thresholds', {
            'health_score_min': 70.0,
            'error_rate_max': 0.1,
            'timeout_rate_max': 0.05,
            'satisfaction_min': 3.5,
            'adoption_rate_min': 0.3
        })
    
    def detect_deviations(self, metrics: SkillPerformanceMetrics) -> List[Dict[str, Any]]:
        """æ£€æµ‹åå·®"""
        deviations = []
        
        # å¥åº·åº¦æ£€æŸ¥
        if metrics.health_score < self.thresholds['health_score_min']:
            deviations.append({
                'type': 'low_health_score',
                'severity': 'high',
                'current_value': metrics.health_score,
                'threshold': self.thresholds['health_score_min'],
                'description': f"å¥åº·åº¦ä½äºé˜ˆå€¼: {metrics.health_score:.1f} < {self.thresholds['health_score_min']}"
            })
        
        # é”™è¯¯ç‡æ£€æŸ¥
        if metrics.error_rate > self.thresholds['error_rate_max']:
            deviations.append({
                'type': 'high_error_rate',
                'severity': 'high',
                'current_value': metrics.error_rate,
                'threshold': self.thresholds['error_rate_max'],
                'description': f"é”™è¯¯ç‡è¿‡é«˜: {metrics.error_rate:.1%} > {self.thresholds['error_rate_max']:.1%}"
            })
        
        # ç”¨æˆ·æ»¡æ„åº¦æ£€æŸ¥
        if metrics.user_satisfaction > 0 and metrics.user_satisfaction < self.thresholds['satisfaction_min']:
            deviations.append({
                'type': 'low_satisfaction',
                'severity': 'medium',
                'current_value': metrics.user_satisfaction,
                'threshold': self.thresholds['satisfaction_min'],
                'description': f"ç”¨æˆ·æ»¡æ„åº¦è¾ƒä½: {metrics.user_satisfaction:.1f} < {self.thresholds['satisfaction_min']}"
            })
        
        # é‡‡ç”¨ç‡æ£€æŸ¥
        if metrics.user_adoption_rate < self.thresholds['adoption_rate_min']:
            deviations.append({
                'type': 'low_adoption',
                'severity': 'medium',
                'current_value': metrics.user_adoption_rate,
                'threshold': self.thresholds['adoption_rate_min'],
                'description': f"é‡‡ç”¨ç‡è¾ƒä½: {metrics.user_adoption_rate:.1%} < {self.thresholds['adoption_rate_min']:.1%}"
            })
        
        return deviations
    
    def analyze_trends(self, historical_metrics: List[SkillPerformanceMetrics]) -> List[Dict[str, Any]]:
        """åˆ†æè¶‹åŠ¿"""
        if len(historical_metrics) < 2:
            return []
        
        trends = []
        recent = historical_metrics[-1]
        previous = historical_metrics[-2]
        
        # å¥åº·åº¦è¶‹åŠ¿
        health_trend = recent.health_score - previous.health_score
        if abs(health_trend) > 5:  # å˜åŒ–è¶…è¿‡5åˆ†
            trends.append({
                'type': 'health_trend',
                'direction': 'declining' if health_trend < 0 else 'improving',
                'change': health_trend,
                'description': f"å¥åº·åº¦{'ä¸‹é™' if health_trend < 0 else 'æå‡'} {abs(health_trend):.1f} åˆ†"
            })
        
        # é”™è¯¯ç‡è¶‹åŠ¿
        error_trend = recent.error_rate - previous.error_rate
        if abs(error_trend) > 0.02:  # å˜åŒ–è¶…è¿‡2%
            trends.append({
                'type': 'error_rate_trend',
                'direction': 'increasing' if error_trend > 0 else 'decreasing',
                'change': error_trend,
                'description': f"é”™è¯¯ç‡{'ä¸Šå‡' if error_trend > 0 else 'ä¸‹é™'} {abs(error_trend):.1%}"
            })
        
        return trends


class SkillOptimizationEngine:
    """Skillä¼˜åŒ–å¼•æ“"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.tracker = SkillPerformanceTracker()
        self.deviation_detector = SkillDeviationDetector(config)

        # ä¼˜åŒ–ç­–ç•¥é…ç½®
        self.optimization_strategies = {
            'parameter': self._optimize_parameters,
            'template': self._optimize_template,
            'documentation': self._optimize_documentation,
            'enhancement': self._enhance_functionality
        }
    
    def analyze_skill_performance(self, skill_name: Optional[str] = None, 
                                 days: int = 30) -> Tuple[List[SkillPerformanceMetrics], List[OptimizationRecommendation]]:
        """åˆ†æSkillæ€§èƒ½"""
        # æ”¶é›†æŒ‡æ ‡
        metrics_list = self.tracker.collect_metrics(skill_name, days)
        
        recommendations = []
        
        for metrics in metrics_list:
            # æ£€æµ‹åå·®
            deviations = self.deviation_detector.detect_deviations(metrics)
            
            if deviations:
                # ç”Ÿæˆä¼˜åŒ–å»ºè®®
                recs = self._generate_recommendations(metrics, deviations)
                recommendations.extend(recs)
        
        return metrics_list, recommendations
    
    def _generate_recommendations(self, metrics: SkillPerformanceMetrics, 
                                 deviations: List[Dict[str, Any]]) -> List[OptimizationRecommendation]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        for deviation in deviations:
            rec = self._create_recommendation(metrics, deviation)
            if rec:
                recommendations.append(rec)
        
        return recommendations
    
    def _create_recommendation(self, metrics: SkillPerformanceMetrics, 
                              deviation: Dict[str, Any]) -> Optional[OptimizationRecommendation]:
        """åˆ›å»ºä¼˜åŒ–å»ºè®®"""
        deviation_type = deviation['type']
        
        if deviation_type == 'low_health_score':
            return OptimizationRecommendation(
                skill_name=metrics.skill_name,
                recommendation_type='enhancement',
                priority='high',
                description='Skillæ•´ä½“å¥åº·åº¦è¾ƒä½ï¼Œéœ€è¦å…¨é¢ä¼˜åŒ–',
                expected_impact='æå‡å¥åº·åº¦20-30åˆ†',
                implementation_effort='high',
                specific_actions=[
                    'åˆ†æå¤±è´¥åŸå› å¹¶ä¿®å¤',
                    'ä¼˜åŒ–æ ¸å¿ƒç®—æ³•',
                    'æ”¹è¿›é”™è¯¯å¤„ç†',
                    'æ›´æ–°æ–‡æ¡£å’Œç¤ºä¾‹'
                ],
                current_metrics=metrics.to_dict(),
                target_metrics={'health_score': 85.0}
            )
        
        elif deviation_type == 'high_error_rate':
            return OptimizationRecommendation(
                skill_name=metrics.skill_name,
                recommendation_type='parameter',
                priority='high',
                description='é”™è¯¯ç‡è¿‡é«˜ï¼Œéœ€è¦è°ƒæ•´å‚æ•°å’Œé”™è¯¯å¤„ç†',
                expected_impact='å°†é”™è¯¯ç‡é™ä½åˆ°5%ä»¥ä¸‹',
                implementation_effort='medium',
                specific_actions=[
                    'å¢åŠ è¾“å…¥éªŒè¯',
                    'ä¼˜åŒ–é”™è¯¯å¤„ç†é€»è¾‘',
                    'æ·»åŠ é‡è¯•æœºåˆ¶',
                    'æ”¹è¿›å‚æ•°é»˜è®¤å€¼'
                ],
                current_metrics=metrics.to_dict(),
                target_metrics={'error_rate': 0.05}
            )
        
        elif deviation_type == 'low_satisfaction':
            return OptimizationRecommendation(
                skill_name=metrics.skill_name,
                recommendation_type='documentation',
                priority='medium',
                description='ç”¨æˆ·æ»¡æ„åº¦è¾ƒä½ï¼Œéœ€è¦æ”¹è¿›æ–‡æ¡£å’Œç”¨æˆ·ä½“éªŒ',
                expected_impact='æå‡ç”¨æˆ·æ»¡æ„åº¦åˆ°4.0ä»¥ä¸Š',
                implementation_effort='low',
                specific_actions=[
                    'ç®€åŒ–ä½¿ç”¨è¯´æ˜',
                    'æ·»åŠ æ›´å¤šç¤ºä¾‹',
                    'æ”¹è¿›è¾“å‡ºæ ¼å¼',
                    'å¢åŠ å¸¸è§é—®é¢˜è§£ç­”'
                ],
                current_metrics=metrics.to_dict(),
                target_metrics={'user_satisfaction': 4.0}
            )
        
        elif deviation_type == 'low_adoption':
            return OptimizationRecommendation(
                skill_name=metrics.skill_name,
                recommendation_type='enhancement',
                priority='medium',
                description='é‡‡ç”¨ç‡è¾ƒä½ï¼Œéœ€è¦å¢åŠ åŠŸèƒ½å’Œæ”¹è¿›æ¨å¹¿',
                expected_impact='æå‡é‡‡ç”¨ç‡åˆ°50%ä»¥ä¸Š',
                implementation_effort='medium',
                specific_actions=[
                    'åˆ†æç”¨æˆ·éœ€æ±‚',
                    'å¢åŠ ç¼ºå¤±åŠŸèƒ½',
                    'æ”¹è¿›æ¨å¹¿ç­–ç•¥',
                    'æ”¶é›†ç”¨æˆ·åé¦ˆ'
                ],
                current_metrics=metrics.to_dict(),
                target_metrics={'user_adoption_rate': 0.5}
            )
        
        return None
    
    def _optimize_parameters(self, skill_name: str, metrics: SkillPerformanceMetrics) -> bool:
        """ä¼˜åŒ–å‚æ•°"""
        print(f"ä¼˜åŒ–Skillå‚æ•°: {skill_name}")

        try:
            # æŸ¥æ‰¾Skillè·¯å¾„
            skill_path = Path('.claude/skills') / skill_name
            if not skill_path.exists():
                print(f"Skillè·¯å¾„ä¸å­˜åœ¨: {skill_path}")
                return False

            # è¯»å–SKILL.md
            skill_md_path = skill_path / 'SKILL.md'
            if not skill_md_path.exists():
                print(f"SKILL.mdä¸å­˜åœ¨")
                return False

            with open(skill_md_path, 'r', encoding='utf-8') as f:
                content = f.read()

            changes_made = False

            # åŸºäºé”™è¯¯ç‡ä¼˜åŒ–è¶…æ—¶å‚æ•°
            if metrics.error_rate > 0.1:
                print(f"  - é”™è¯¯ç‡è¿‡é«˜({metrics.error_rate:.1%})ï¼Œè°ƒæ•´è¶…æ—¶å’Œé‡è¯•å‚æ•°")

                # æ£€æŸ¥æ˜¯å¦æœ‰è¶…æ—¶é…ç½®
                if 'timeout' in content.lower() or 'retry' in content.lower():
                    # å¢åŠ è¶…æ—¶æ—¶é—´å»ºè®®
                    timeout_suggestion = "\n### å‚æ•°ä¼˜åŒ–å»ºè®®\n\nåŸºäºæ€§èƒ½åˆ†æï¼Œå»ºè®®è°ƒæ•´ä»¥ä¸‹å‚æ•°:\n- `timeout`: å»ºè®®å¢åŠ è‡³ 60 ç§’\n- `max_retries`: å»ºè®®è®¾ç½®ä¸º 3 æ¬¡\n- `retry_delay`: å»ºè®®è®¾ç½®ä¸º 2 ç§’\n"

                    if '## ğŸ“‹ è¾“å…¥è§„èŒƒ' in content and '### å‚æ•°ä¼˜åŒ–å»ºè®®' not in content:
                        content = content.replace('## ğŸ“‹ è¾“å…¥è§„èŒƒ', timeout_suggestion + '\n## ğŸ“‹ è¾“å…¥è§„èŒƒ')
                        changes_made = True

            # åŸºäºæ€§èƒ½ä¼˜åŒ–æ‰¹å¤„ç†å‚æ•°
            if metrics.avg_duration > 10:
                print(f"  - å¹³å‡æ‰§è¡Œæ—¶é—´è¿‡é•¿({metrics.avg_duration:.2f}ç§’)ï¼Œå»ºè®®å¯ç”¨æ‰¹å¤„ç†")

                batch_suggestion = "\n### æ€§èƒ½ä¼˜åŒ–å»ºè®®\n\n- å¯ç”¨æ‰¹å¤„ç†æ¨¡å¼ä»¥æå‡æ€§èƒ½\n- `batch_size`: å»ºè®®è®¾ç½®ä¸º 100\n- `parallel_workers`: å»ºè®®è®¾ç½®ä¸º 4\n"

                if '## ğŸ”§ é«˜çº§åŠŸèƒ½' not in content and changes_made is False:
                    content += f"\n{batch_suggestion}\n"
                    changes_made = True

            # åŸºäºç”¨æˆ·åé¦ˆä¼˜åŒ–é»˜è®¤å‚æ•°
            if metrics.user_satisfaction < 3.5 and metrics.satisfaction_count > 5:
                print(f"  - ç”¨æˆ·æ»¡æ„åº¦è¾ƒä½({metrics.user_satisfaction:.1f})ï¼Œä¼˜åŒ–é»˜è®¤å‚æ•°")

                # æ·»åŠ ç”¨æˆ·å‹å¥½çš„é»˜è®¤å€¼å»ºè®®
                default_suggestion = "\n### é»˜è®¤å‚æ•°ä¼˜åŒ–\n\nåŸºäºç”¨æˆ·åé¦ˆä¼˜åŒ–:\n- å¢åŠ è¾“å‡ºè¯¦ç»†åº¦\n- æä¾›æ›´å‹å¥½çš„é”™è¯¯æç¤º\n- æ·»åŠ è¿›åº¦æ˜¾ç¤º\n"

                if changes_made is False:
                    content += f"\n{default_suggestion}\n"
                    changes_made = True

            # ä¿å­˜æ›´æ–°
            if changes_made:
                with open(skill_md_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"  âœ… å‚æ•°ä¼˜åŒ–å»ºè®®å·²æ·»åŠ åˆ°æ–‡æ¡£")
                return True
            else:
                print(f"  â„¹ï¸  å½“å‰å‚æ•°é…ç½®è‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–")
                return True

        except Exception as e:
            print(f"å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")
            return False
    
    def _optimize_template(self, skill_name: str, metrics: SkillPerformanceMetrics) -> bool:
        """ä¼˜åŒ–æ¨¡æ¿"""
        print(f"ä¼˜åŒ–Skillæ¨¡æ¿: {skill_name}")
        return True
    
    def _optimize_documentation(self, skill_name: str, metrics: SkillPerformanceMetrics) -> bool:
        """ä¼˜åŒ–æ–‡æ¡£"""
        print(f"ä¼˜åŒ–Skillæ–‡æ¡£: {skill_name}")
        return True
    
    def _enhance_functionality(self, skill_name: str, metrics: SkillPerformanceMetrics) -> bool:
        """å¢å¼ºåŠŸèƒ½"""
        print(f"å¢å¼ºSkillåŠŸèƒ½: {skill_name}")

        try:
            # æŸ¥æ‰¾Skillè·¯å¾„
            skill_path = Path('.claude/skills') / skill_name
            if not skill_path.exists():
                print(f"Skillè·¯å¾„ä¸å­˜åœ¨: {skill_path}")
                return False

            enhancements = []

            # åŸºäºé‡‡ç”¨ç‡ä½ï¼Œå»ºè®®å¢åŠ åŠŸèƒ½
            if metrics.user_adoption_rate < 0.3:
                print(f"  - é‡‡ç”¨ç‡è¾ƒä½({metrics.user_adoption_rate:.1%})ï¼Œåˆ†æç¼ºå¤±åŠŸèƒ½")

                enhancements.append({
                    'type': 'feature',
                    'priority': 'high',
                    'title': 'å¢åŠ ç”¨æˆ·éœ€æ±‚çš„åŠŸèƒ½',
                    'suggestions': [
                        'è°ƒç ”ç”¨æˆ·å®é™…éœ€æ±‚',
                        'å¢åŠ å¸¸ç”¨åŠŸèƒ½å¿«æ·æ–¹å¼',
                        'æä¾›æ›´å¤šè¾“å‡ºæ ¼å¼é€‰é¡¹',
                        'å¢åŠ æ‰¹å¤„ç†æ¨¡å¼æ”¯æŒ'
                    ]
                })

            # åŸºäºé”™è¯¯ç‡ï¼Œå¢åŠ å¥å£®æ€§åŠŸèƒ½
            if metrics.error_rate > 0.1:
                print(f"  - é”™è¯¯ç‡è¿‡é«˜({metrics.error_rate:.1%})ï¼Œå¢å¼ºå¥å£®æ€§")

                enhancements.append({
                    'type': 'robustness',
                    'priority': 'high',
                    'title': 'å¢å¼ºé”™è¯¯å¤„ç†å’Œæ¢å¤èƒ½åŠ›',
                    'suggestions': [
                        'æ·»åŠ è¾“å…¥éªŒè¯æœºåˆ¶',
                        'å®ç°è‡ªåŠ¨é‡è¯•é€»è¾‘',
                        'å¢åŠ é”™è¯¯æ¢å¤ç­–ç•¥',
                        'æä¾›è¯¦ç»†çš„é”™è¯¯è¯Šæ–­ä¿¡æ¯',
                        'æ·»åŠ é™çº§å¤„ç†æ–¹æ¡ˆ'
                    ]
                })

            # åŸºäºç”¨æˆ·æ»¡æ„åº¦ï¼Œå¢åŠ ç”¨æˆ·ä½“éªŒåŠŸèƒ½
            if metrics.user_satisfaction < 3.5 and metrics.satisfaction_count > 5:
                print(f"  - ç”¨æˆ·æ»¡æ„åº¦è¾ƒä½({metrics.user_satisfaction:.1f})ï¼Œæ”¹å–„ç”¨æˆ·ä½“éªŒ")

                enhancements.append({
                    'type': 'ux',
                    'priority': 'medium',
                    'title': 'æ”¹å–„ç”¨æˆ·ä½“éªŒ',
                    'suggestions': [
                        'æ·»åŠ è¿›åº¦æ¡å’ŒçŠ¶æ€æç¤º',
                        'ä¼˜åŒ–è¾“å‡ºæ ¼å¼çš„å¯è¯»æ€§',
                        'æä¾›äº¤äº’å¼é…ç½®å‘å¯¼',
                        'å¢åŠ ä½¿ç”¨æç¤ºå’Œå¸®åŠ©ä¿¡æ¯',
                        'ç®€åŒ–å¸¸ç”¨æ“ä½œæµç¨‹'
                    ]
                })

            # åŸºäºæ€§èƒ½ï¼Œå¢åŠ ä¼˜åŒ–åŠŸèƒ½
            if metrics.avg_duration > 10:
                print(f"  - å¹³å‡æ‰§è¡Œæ—¶é—´è¿‡é•¿({metrics.avg_duration:.2f}ç§’)ï¼Œå¢åŠ æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½")

                enhancements.append({
                    'type': 'performance',
                    'priority': 'high',
                    'title': 'æ€§èƒ½ä¼˜åŒ–å¢å¼º',
                    'suggestions': [
                        'å®ç°å¢é‡å¤„ç†æ¨¡å¼',
                        'æ·»åŠ ç¼“å­˜æœºåˆ¶',
                        'æ”¯æŒå¹¶è¡Œå¤„ç†',
                        'ä¼˜åŒ–èµ„æºä½¿ç”¨',
                        'å®ç°æ‡’åŠ è½½ç­–ç•¥'
                    ]
                })

            # å†™å…¥å¢å¼ºå»ºè®®æ–‡æ¡£
            if enhancements:
                enhancement_doc_path = skill_path / 'ENHANCEMENT_RECOMMENDATIONS.md'

                enhancement_content = f"""# {skill_name} åŠŸèƒ½å¢å¼ºå»ºè®®

> åŸºäºæ€§èƒ½åˆ†æè‡ªåŠ¨ç”Ÿæˆ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š å½“å‰æ€§èƒ½æŒ‡æ ‡

- å¥åº·åº¦è¯„åˆ†: {metrics.health_score:.1f}/100
- ç”¨æˆ·æ»¡æ„åº¦: {metrics.user_satisfaction:.1f}/5.0
- é‡‡ç”¨ç‡: {metrics.user_adoption_rate:.1%}
- é”™è¯¯ç‡: {metrics.error_rate:.1%}
- å¹³å‡æ‰§è¡Œæ—¶é—´: {metrics.avg_duration:.2f}ç§’

## ğŸš€ å¢å¼ºå»ºè®®

"""

                for idx, enhancement in enumerate(enhancements, 1):
                    enhancement_content += f"""
### {idx}. {enhancement['title']} ({enhancement['type'].upper()})

**ä¼˜å…ˆçº§**: {enhancement['priority'].upper()}

**å…·ä½“å»ºè®®**:
"""
                    for suggestion in enhancement['suggestions']:
                        enhancement_content += f"- {suggestion}\n"

                    enhancement_content += "\n"

                enhancement_content += """
## ğŸ“‹ å®æ–½è®¡åˆ’

1. **è¯„ä¼°é˜¶æ®µ** (1-2å¤©)
   - ä¸ç”¨æˆ·æ²Ÿé€šç¡®è®¤éœ€æ±‚
   - è¯„ä¼°å®æ–½æˆæœ¬å’Œæ”¶ç›Š
   - ç¡®å®šä¼˜å…ˆçº§

2. **è®¾è®¡é˜¶æ®µ** (2-3å¤©)
   - è®¾è®¡å¢å¼ºæ–¹æ¡ˆ
   - è¯„å®¡æŠ€æœ¯å¯è¡Œæ€§
   - å‡†å¤‡æµ‹è¯•è®¡åˆ’

3. **å®æ–½é˜¶æ®µ** (5-10å¤©)
   - æŒ‰ä¼˜å…ˆçº§å®æ–½å¢å¼º
   - ç¼–å†™å•å…ƒæµ‹è¯•
   - æ›´æ–°æ–‡æ¡£

4. **éªŒè¯é˜¶æ®µ** (2-3å¤©)
   - åŠŸèƒ½æµ‹è¯•
   - æ€§èƒ½æµ‹è¯•
   - ç”¨æˆ·éªŒæ”¶æµ‹è¯•

## âš ï¸ æ³¨æ„äº‹é¡¹

- æ‰€æœ‰å¢å¼ºéœ€è¦ç»è¿‡å……åˆ†æµ‹è¯•
- ä¿æŒå‘åå…¼å®¹æ€§
- åŠæ—¶æ›´æ–°æ–‡æ¡£å’Œç¤ºä¾‹
- æ”¶é›†ç”¨æˆ·åé¦ˆå¹¶è¿­ä»£
"""

                try:
                    with open(enhancement_doc_path, 'w', encoding='utf-8') as f:
                        f.write(enhancement_content)
                    print(f"  âœ… åŠŸèƒ½å¢å¼ºå»ºè®®å·²ä¿å­˜åˆ°: {enhancement_doc_path}")

                    # åŒæ—¶åœ¨SKILL.mdä¸­æ·»åŠ å¼•ç”¨
                    skill_md_path = skill_path / 'SKILL.md'
                    if skill_md_path.exists():
                        with open(skill_md_path, 'r', encoding='utf-8') as f:
                            skill_content = f.read()

                        if 'ENHANCEMENT_RECOMMENDATIONS.md' not in skill_content:
                            enhancement_link = f"\n\n> ğŸ’¡ **åŠŸèƒ½å¢å¼ºå»ºè®®**: æŸ¥çœ‹ [ENHANCEMENT_RECOMMENDATIONS.md](./ENHANCEMENT_RECOMMENDATIONS.md) äº†è§£åŸºäºæ€§èƒ½åˆ†æçš„æ”¹è¿›å»ºè®®\n"

                            # åœ¨æ–‡æ¡£æœ«å°¾æ·»åŠ é“¾æ¥
                            skill_content += enhancement_link

                            with open(skill_md_path, 'w', encoding='utf-8') as f:
                                f.write(skill_content)
                            print(f"  âœ… å·²åœ¨SKILL.mdä¸­æ·»åŠ å¢å¼ºå»ºè®®é“¾æ¥")

                    return True

                except Exception as e:
                    print(f"ä¿å­˜å¢å¼ºå»ºè®®å¤±è´¥: {e}")
                    return False

            else:
                print(f"  â„¹ï¸  å½“å‰åŠŸèƒ½æ»¡è¶³éœ€æ±‚ï¼Œæ— éœ€å¢å¼º")
                return True

        except Exception as e:
            print(f"åŠŸèƒ½å¢å¼ºå¤±è´¥: {e}")
            return False
    
    def apply_optimization(self, recommendation: OptimizationRecommendation) -> bool:
        """åº”ç”¨ä¼˜åŒ–"""
        strategy = self.optimization_strategies.get(recommendation.recommendation_type)
        if not strategy:
            return False
        
        try:
            # è·å–å½“å‰æŒ‡æ ‡
            metrics_list = self.tracker.collect_metrics(recommendation.skill_name, 30)
            if not metrics_list:
                return False
            
            metrics = metrics_list[0]
            
            # åº”ç”¨ä¼˜åŒ–ç­–ç•¥
            return strategy(recommendation.skill_name, metrics)
            
        except Exception as e:
            print(f"åº”ç”¨ä¼˜åŒ–å¤±è´¥: {e}")
            return False
    
    def generate_optimization_report(self, metrics_list: List[SkillPerformanceMetrics],
                                    recommendations: List[OptimizationRecommendation],
                                    output_file: Optional[str] = None) -> Dict[str, Any]:
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        report = {
            'generated_at': datetime.now().isoformat(),
            'analysis_period_days': 30,
            'total_skills_analyzed': len(metrics_list),
            'skills_needing_optimization': len(recommendations),
            'overall_health': {
                'average_health_score': sum(m.health_score for m in metrics_list) / len(metrics_list) if metrics_list else 0,
                'high_performing_skills': len([m for m in metrics_list if m.health_score >= 80]),
                'underperforming_skills': len([m for m in metrics_list if m.health_score < 60])
            },
            'skill_metrics': [m.to_dict() for m in metrics_list],
            'optimization_recommendations': [r.to_dict() for r in recommendations],
            'priority_summary': {
                'high_priority': len([r for r in recommendations if r.priority == 'high']),
                'medium_priority': len([r for r in recommendations if r.priority == 'medium']),
                'low_priority': len([r for r in recommendations if r.priority == 'low'])
            }
        }
        
        if output_file:
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(report, f, ensure_ascii=False, indent=2)
                print(f"ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
            except Exception as e:
                print(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
        
        return report


# å…¨å±€ä¼˜åŒ–å¼•æ“å®ä¾‹
optimization_engine = SkillOptimizationEngine()


def get_optimization_engine() -> SkillOptimizationEngine:
    """è·å–ä¼˜åŒ–å¼•æ“å®ä¾‹"""
    return optimization_engine


if __name__ == '__main__':
    # æµ‹è¯•ä¼˜åŒ–å¼•æ“
    engine = SkillOptimizationEngine()
    
    # åˆ†ææ‰€æœ‰Skillæ€§èƒ½
    metrics, recommendations = engine.analyze_skill_performance(days=7)
    
    print(f"åˆ†æå®Œæˆ: {len(metrics)} ä¸ªSkillï¼Œ{len(recommendations)} æ¡ä¼˜åŒ–å»ºè®®")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = engine.generate_optimization_report(metrics, recommendations)
    print(json.dumps(report, ensure_ascii=False, indent=2))